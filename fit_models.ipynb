{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:51:06.812478Z",
     "start_time": "2024-05-21T16:51:06.572007Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from catboost import CatBoostClassifier\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data = pd.read_csv(\"data/Twitter_Data.csv\")\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:18:50.484532Z",
     "start_time": "2024-05-21T16:18:50.389687Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"shape with NaN values: {data.shape}\")\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "\n",
    "print(f\"shape without NaN values: {data.shape}\")\n",
    "\n",
    "data.head()\n",
    "\n",
    "reviews = [\"-1\", \"0\", \"1\"]\n",
    "number_of_reviews = [data['category'].value_counts()[x] for x in range(-1, 2)]\n",
    "\n",
    "#define Seaborn color palette to use\n",
    "colors = sns.light_palette('seagreen')[0:3]\n",
    "\n",
    "#create pie chart\n",
    "plt.pie(number_of_reviews, labels=reviews, colors=colors, autopct='%.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:18:55.106330Z",
     "start_time": "2024-05-21T16:18:54.746908Z"
    }
   },
   "outputs": [],
   "source": [
    "def delete_punctuation_from_string(s: str):\n",
    "    return re.sub(r'[^\\w\\s]', '', s)\n",
    "\n",
    "\n",
    "data.loc[:, \"clean_text\"] = data[\"clean_text\"].astype(str)\n",
    "data.loc[:, \"clean_text\"] = data[\"clean_text\"].apply(delete_punctuation_from_string)\n",
    "\n",
    "train, test = train_test_split(data, random_state=239)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "\n",
    "x_train = bow.fit_transform(train[\"clean_text\"])\n",
    "x_test = bow.transform(test[\"clean_text\"])\n",
    "y_train = train[\"category\"]\n",
    "y_test = test[\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:19:00.030970Z",
     "start_time": "2024-05-21T16:18:57.162317Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t = time.time()\n",
    "cbc = CatBoostClassifier(task_type='GPU', learning_rate=0.3, iterations=500)\n",
    "cbc.fit(x_train, y_train, verbose=False)\n",
    "print(time.time() - t)\n",
    "\n",
    "# 116.26442384719849\n",
    "# 0.9301598458959877\n",
    "\n",
    "# 113.65503215789795 0.3 / 1000\n",
    "# 0.9374714628447963\n",
    "\n",
    "# 152.65503215789795 0.3 / 1500\n",
    "# 0.9374714628447963\n",
    "\n",
    "# 155.61173748970032\n",
    "# 0.9399550699946421\n",
    "\n",
    "# 95.837233543396\n",
    "# 0.8826353364534069\n",
    "\n",
    "y_pred = cbc.predict(x_test)\n",
    "\n",
    "print(balanced_accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appeared that in case either lemmatization or deleting stopwords is applied, the accuracy is noticeably higher than with both approaches applied. Will be used just lemmatization (or maybe ensembling with stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatize(x):\n",
    "    x = map(lambda r: ' '.join([l.lemmatize(i.lower()) for i in r.split()]), x)\n",
    "    x = np.array(list(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T17:03:33.619983Z",
     "start_time": "2024-05-21T17:03:22.314878Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "def delete_stop_word(s):\n",
    "    words = s.split()\n",
    "    return \" \".join([word for word in words if word.lower() not in stop_words])\n",
    "\n",
    "\n",
    "# apply lemmatization\n",
    "train[\"clean_text\"] = lemmatize(train[\"clean_text\"])\n",
    "test[\"clean_text\"] = lemmatize(test[\"clean_text\"])\n",
    "\n",
    "# delete stop words\n",
    "train_no_sw = train[\"clean_text\"].apply(delete_stop_word)\n",
    "test_no_sw = test[\"clean_text\"].apply(delete_stop_word)\n",
    "\n",
    "bow = CountVectorizer()\n",
    "\n",
    "x_train = bow.fit_transform(train_no_sw)\n",
    "x_test = bow.transform(test_no_sw)\n",
    "y_train = train[\"category\"]\n",
    "y_test = test[\"category\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch suggests that iterations=1500, depth=9 and learning_rate=0.3 are optimal hyperparameters with test score accuracy: 0.8937240753012787. But even with iterations=9 and learning_rate=0.3 - all is ok (accuracy: 0.92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:25:10.767077Z",
     "start_time": "2024-05-20T13:40:43.984535Z"
    }
   },
   "outputs": [],
   "source": [
    "cb_model = CatBoostClassifier(verbose=False)\n",
    "\n",
    "cb_param_grid = {\n",
    "    'iterations': [500, 1000, 1500],\n",
    "    'depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.1, 0.15, 0.2, 0.3],\n",
    "}\n",
    "\n",
    "cb_gs = GridSearchCV(estimator=cb_model, param_grid=cb_param_grid, cv=3, n_jobs=-1, verbose=3)\n",
    "\n",
    "cb_gs.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", cb_gs.best_params_)\n",
    "print(\"Best score:\", cb_gs.best_score_)\n",
    "\n",
    "best_model = cb_gs.best_estimator_\n",
    "test_score = best_model.score(x_test, y_test)\n",
    "print(\"Test set score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:08:55.669015Z",
     "start_time": "2024-05-21T15:06:34.611114Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier(iterations=1500, learning_rate=0.3, task_type='GPU', verbose=True)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# lemmatized + without stopwords -> 0.89\n",
    "# lemmatized -> 0.926\n",
    "# without stopwords -> 0.9023\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(\"CatBoost\", balanced_accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:23:48.271479Z",
     "start_time": "2024-05-21T16:23:44.334457Z"
    }
   },
   "outputs": [],
   "source": [
    "logr = LogisticRegression(verbose=True)\n",
    "logr.fit(x_train, y_train)\n",
    "\n",
    "# lemmatized + without stopwords -> 0.884258\n",
    "# lemmatized -> 0.925\n",
    "# without stopwords -> 0.89744\n",
    "\n",
    "y_pred = logr.predict(x_test)\n",
    "\n",
    "print(\"Logistic\", balanced_accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T17:06:31.889586Z",
     "start_time": "2024-05-21T17:03:40.453981Z"
    }
   },
   "outputs": [],
   "source": [
    "log_r_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "# Logistic regression hyper-param tuning\n",
    "logr_gs = GridSearchCV(estimator=LogisticRegression(), param_grid=log_r_param_grid, cv=5, n_jobs=-1, verbose=3)\n",
    "logr_gs.fit(x_train, y_train)\n",
    "\n",
    "# for lemmatized\n",
    "# Best score: 0.92647\n",
    "# Best params: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'} \n",
    "\n",
    "# without stopwords\n",
    "# Best score: 0.9018457653217304\n",
    "# Best params: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "\n",
    "# lemmatized + no stopwords\n",
    "# Best score: 0.8887225379954671\n",
    "# Best params: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "\n",
    "print(\"Best score:\", logr_gs.best_score_)\n",
    "print(\"Best params:\", logr_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:25:52.057658Z",
     "start_time": "2024-05-21T15:25:06.966907Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(verbose=True, n_jobs=-1, n_estimators=10)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# lemmatized + without stopwords -> 0.84985\n",
    "# lemmatized -> 0.8482033\n",
    "# without stopwords -> 0.8480635\n",
    "\n",
    "y_pred = rf.predict(x_test)\n",
    "\n",
    "print(\"Random forest\", balanced_accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T16:56:35.227864Z",
     "start_time": "2024-05-21T16:52:45.643292Z"
    }
   },
   "outputs": [],
   "source": [
    "# Computationally demanding. Will not tune paramemters\n",
    "\n",
    "rf_grid_params = {'max_features': [1, 3, 5, 7],\n",
    "                  'min_samples_leaf': [1, 2, 3],\n",
    "                  'min_samples_split': [1, 2, 3]\n",
    "                  }\n",
    "\n",
    "rf_hype = RandomForestClassifier(verbose=False, n_jobs=-1)\n",
    "\n",
    "rf_gs = RandomizedSearchCV(estimator=rf_hype, param_distributions=rf_grid_params, cv=5, verbose=3)\n",
    "rf_gs.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best score:\", rf_gs.best_score_)\n",
    "print(\"Best params:\", rf_gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried LogisticRegression and RandomForestClassifier with no hyperparameter tuning and both display a reasonable accuracy: LR - 0.89744, RF - 0.86577\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"models/model_catboost\", 'wb') as model_file:\n",
    "    pickle.dump(cbc, model_file)\n",
    "\n",
    "with open(\"models/model_logisticregression\", 'wb') as model_file:\n",
    "    pickle.dump(logr, model_file)\n",
    "\n",
    "with open(\"models/model_randomforest\", 'wb') as model_file:\n",
    "    pickle.dump(rf, model_file)\n",
    "\n",
    "with open(\"models/model_bow\", 'wb') as file:\n",
    "    pickle.dump(bow, file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interactor import Interactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelsObj = Interactor(models_path=\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelsObj.predict(model_name=\"catboost\", sentence=\"AMAZING I LOVE YOU ALL THERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
